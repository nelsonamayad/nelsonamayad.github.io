---
title: "Plato, cocina, receta, ingredientes #2"
subtitle: "Receta para un plato mixto"
author: "Nelson Amaya"
output: 
  html_document:
      theme: readable
      code_folding: hide
---
<br>
Twitter: [`@nelsonamayad`](https://twitter.com/NelsonAmayaD)
<br>
Publicación: **25-04-2018**
<br>
Última actualización: **19-05-2018**
<br>
<br>
```{r setup, include=FALSE}
options(Encoding="UTF-8")
knitr::opts_chunk$set(echo = TRUE)
```
> *"Linear regression is the geocentric model of applied statistics."*<br>
- [Richard McElreath](https://twitter.com/rlmcelreath)

<br>
La [primera receta](https://nelsonamayad.github.io/receta) para hacerle seguimiento a las encuestas logra mucho con muy poco. Pero desaprovecha [la poca información que hay](https://nelsonamayad.shinyapps.io/col2018_tend/).

Esta segunda receta le saca más jugo a lo poco que hay. Requiere más tiempo en la cocina y usa nuevos ingredientes, pero el resultado lo justifica.

El truco del plato mixto es explotar relaciones *entre* las características de las encuestas; por ejemplo, que las encuestas más pequeñas son, a la vez, las que se hacen por teléfono. En términos estadísticos, esta receta es un modelo mixto que extiende los efectos aleatorios por encuestadora que tenía la primera receta ($\alpha_{encuestadora[i]}$) a los coeficientes de las otras variables explicativas ($\beta_{encuestadora[i]}$).

¿Qué se logra con eso? Un mejor plato. ¿Por qué? No tengo la menor idea sobre cómo decir eso en español, o en metáfora culinaria, pero la idea es que cuando hay clusters que no tienen un órden determinado en los datos, como en este caso son las encuestadoras, se puede modelar simultáneamente lo que está *dentro* esos clusters y usar esas inferencias para **agrupar** (*pool*) información *entre* parámetros.

Siéntase libre de leer por encima, o ignorar, lo que le parezca demasiado técnico. No se pierde de mucho. De cualquier forma, la apuesta de este ejercicio no cambia: la transparencia es algo que se hace, no algo que se dice. Aquí no hay salsa secreta.

Buen provecho

***

## Plato
<br>
Primero veamos cómo se comparan los resultados del segundo plato *mixto* con los del primer plato [*simple* ](https://nelsonamayad.github.io/simple/simple). Solo se comparan los promedios para facilitar la visualización; eso no significa que cada punto del plato mixto no tenga su correspondiente intervalo de credibilidad, solo que ese intervalo no se muestra. 

*Los valores cambian con cada estimación*. Eso refleja la incorporación de nueva información y la forma como la receta los procesa. 

<br>
```{r, echo=F, message=F}
library(tidyverse)
#Platos 1 y 2:
platos <- tribble(~candidato,~int_voto,~int_voto_max,~int_voto_min,~m_03.2018,~plato,
  "Sergio Fajardo",15.9,17.2,14.4,13.1,"Plato Simple",
  "Gustavo Petro",27.5,31.5,23.7,26.8,"Plato Simple",
  "Ivan Duque",40.4,43.2,37.5,38.1,"Plato Simple",
  "Humberto de la Calle",2.2,3.2,1,3,"Plato Simple",
  "German Vargas Lleras",6.7,7.9,5.6,6.6,"Plato Simple",
  "Sergio Fajardo",15.8,17.3,14.2,13.1,"Plato Mixto",
  "Gustavo Petro",30.1,33.3,26.9,26.8,"Plato Mixto",
  "Ivan Duque",40.1,43.2,38.7,38.1,"Plato Mixto",
  "Humberto de la Calle",2,3.2,1.1,3,"Plato Mixto",
  "German Vargas Lleras",7.2,8.6,5.8,6.6,"Plato Mixto")

#Orden                
platos <- platos %>% mutate(candidato=factor(candidato,levels=c("Humberto de la Calle","German Vargas Lleras","Sergio Fajardo","Gustavo Petro","Ivan Duque")),plato=factor(plato))

#Platos comparados:
ggplot(platos, aes(x=candidato, color=candidato))+
  #plato
  geom_point(aes(y=int_voto))+
  geom_text(aes(y=int_voto,label=format(int_voto,digits=2)),vjust=-1, size=5)+
  geom_hline(yintercept=c(10,20,30,40,50),linetype="dashed",color="grey60")+
  #referencias
  geom_point(aes(y=m_03.2018), shape=9,size=5)+
  geom_text(aes(y=m_03.2018, label="11.03.2018",angle=90),size=2,hjust=1.4)+
  coord_flip()+
  #facet
  facet_wrap(~plato)+
  theme(legend.position="none",
        panel.background=element_rect(fill="white",color="white"),text = element_text(size=15))+
  labs(x="",y="% de votos estimados - 1era vuelta")+
  scale_y_continuous(limits =c(0,50),breaks=c(10,20,30,40,50))+
  scale_color_manual(values=c("red4","red2","green4","gold2","orangered")) +
  scale_fill_manual(values=c("red4","red2","green4","gold2", "orangered"))
```
<br>

***
## Ingredientes
<br>
Esta receta utiliza la misma información que la anterior: las encuestas que han salido después de las elecciones legislativas del 11 de marzo.

#### *Encuestas*

Las encuestas se importan desde GitHub con RCurl:

``` {r, echo = T, message=F}
library(RCurl)

# Importar encuestas desde GitHub:
encuestas <- read.csv(text=getURL("https://raw.githubusercontent.com/nelsonamayad/Elecciones-presidenciales-2018/master/Elecciones%202018/encuestas2018.csv"))
```

#### *Priors*

Este modelo comienza con los mismos priors del plato simple:

``` {r, echo = T}
library(tidyverse)
library(kableExtra)

# Preparar data frame para calcular priors
priors <- encuestas %>% select(n,fecha,ivan_duque,gustavo_petro,sergio_fajardo,german_vargas_lleras,humberto_delacalle) %>% filter(as.Date(fecha)>as.Date("2018-03-11"))
priors <- priors %>% select(-n,-fecha) %>% gather(candidato, int_voto)

# Calcular priors
priors <- priors %>% group_by(candidato) %>% mutate(prior_mu=mean(int_voto),prior_sigma=sd(int_voto))
priors <- priors %>% distinct(prior_mu,prior_sigma) 

# Tabla de priors
priors %>% kable("html", digits=0,caption = "Priors por candidato") %>% kable_styling(full_width = F)
```
<br>
Pero es no es todo. Como este plato modela la relación entre todas las caraterísticas de las encuestas, necesita priors para las varianzas y correlaciones entre *todos* los parámetros. 

**Advertencia: lo que viene es técnico pero importante**

El plato mixto utiliza un prior específico con la distribución [Lewandowski-Kurowicka-Joe (LKJ para sus amigos)](https://www.sciencedirect.com/science/article/pii/S0047259X09000876), que permite definir con un sólo parámetro $\eta$ la diagnonal de la matriz de correlación. 

Utilizando el prior $\eta=2$ las correlaciones están débilmente informadas y son escépticas de niveles extremos como -1 (perfecta correlación negativa) o 1 (perfecta correlación positiva). Ese es el prior que recomiendan el manual de [Stan](https://github.com/stan-dev/stan/releases/download/v2.17.0/stan-reference-2.17.0.pdf) y texto McElreath para situaciones en las que esas relaciones no se conocen muy bien.

No voy a decir más sobre esto excepto que este truco permite lo que el plato mixto busca hacer: aprovechar mejor la poca información que hay. 

***

## Receta
<br>
Esta receta tiene la misma base que la anterior. La proporción de votos para cada candidato sale de modelo lineal sobre características observables de las encuestas: 1) el tamaño de la muestra de cada encuesta (*m*), 2) el márgen de error de la encuesta (*e*), 3) los días que pasaron entre la encuesta y la estimación (*d*), 4) una dummy para el tipo de encuesta (telefónica o presencial) (*tipo*). 

La diferencia entre esta receta y la anterior es añadir ($\beta_{encuestadora[i]}$) a los coeficientes de las otras variables explicativas. Suena simple pero no lo es: implica incluir una matriz de varianza/covarianza que describe cómo se relaciona la distribución posterior de cada parámetro con los otros (ver capítulo 13 de [*Statistical Rethinking*](http://xcelab.net/rm/statistical-rethinking/)).

***
## Preparación
<br>
Este es el modelo con los respectivos priors para cada parámetro. Nuevamente, los únicos priors informados son los que determinan el parámetro que captura el promedio y desviación estándar de cada candidato. El otro prior clave es el que va en la matriz de correlación LKJ. 

Nunca fui muy hábil en álgebra lineal, así que esto va con uno que otro detalle innecesario y de pronto un horror en notación:

$$\small \lambda_{candidato,t} \sim Normal(\mu_{candidato,t},\sigma_{candidato,t})$$
$$\small \mu_{candidato,t} = \alpha_{encuestadora[i]}+\beta_{1,encuestadora[i]}*m+\beta_{2,encuestadora[i]}*e+\beta_{3,encuestadora[i]}*d+\beta_{4,encuestadora[i]}*tipo $$
$$\left[\begin{array}
{rrr}
\alpha_{encuestadora[i]}\\
\beta_{1,encuestadora[i]}\\
\beta_{2,encuestadora[i]}\\
\beta_{3,encuestadora[i]}\\
\beta_{4,encuestadora[i]}\\
\end{array}\right]
= MVNormal
\Bigg(
\left[\begin{array}
{rrr}
\alpha_{encuestadora[i]}\\
\beta_{1,encuestadora[i]}\\
\beta_{2,encuestadora[i]}\\
\beta_{3,encuestadora[i]}\\
\beta_{4,encuestadora[i]}\\
\end{array}\right],S
\Bigg)$$ 

$$
\mathbf{S} = 
\mathbf{x} \cdot
\mathbf{R} \cdot
\mathbf{x}
$$ 
$$
\mathbf{x} = \left(\begin{array}{rrr} 
\sigma_{\alpha} & 0 & 0 & 0 & 0\\
0 & \sigma_{\beta_1} & 0 & 0 & 0\\
0 & 0 & \sigma_{\beta_2} & 0 & 0\\
0 & 0 & 0 & \sigma_{\beta_3} & 0\\
0 & 0 & 0 & 0 & \sigma_{\beta_4}\\
\end{array}\right)
$$
$$
\mathbf{R} \sim LKJcorr(2)
$$

$$\small\alpha_{encuestadora} \sim Normal(\mu_{candidato},\sigma_{candidato}) $$

$$\small\beta_1,\beta_2,\beta_3,\beta_4 \sim Normal(0,10) $$

$$\small\beta_{encuestadora} \sim Normal(\mu, \sigma) $$

$$\small\mu \sim Normal(0,10) $$

$$\small\sigma \sim HalfCauchy(0,5) $$

$$\small\sigma_{candidato} \sim HalfCauchy(0,5)$$

#### *Alistamiento de los datos*
<br>
Este paso es idéntico al del plato [*simple*](https://nelsonamayad.github.io/receta): 
<br>
```{r, echo=T, message=F}
library(lubridate)

#1. Depurar encuestas:
df <- encuestas %>% select(n,fecha, encuestadora,ivan_duque,gustavo_petro,sergio_fajardo,german_vargas_lleras, humberto_delacalle, margen_error,tipo, muestra_int_voto)

#2. Solo las encuestas post 2018-03-11:
df <- df %>% filter(as.Date(fecha, tz="GMT") >= as.Date('2018-03-11', tz="GMT"))

#3. Crear variable duracion:
df <- df %>% mutate(dd = as.Date(as.character(today()), format="%Y-%m-%d") - as.Date(as.character(fecha), format="%Y-%m-%d"))
df <- df %>% mutate(dd = as.numeric(dd))
df <- df %>% mutate(dd = 100*(dd/sum(dd)))

#4. Codificar encuestadoras:
df <- df %>% mutate(enc=encuestadora)
df$encuestadora <- match(df$encuestadora, unique(df$encuestadora))

#5. Dummy tipo de encuesta (=1 si presencial):
df <- df %>% mutate(tipo=ifelse(tipo=="Presencial",1,0))

#6. Otros ajustes:
df <- df %>% rename(m_error = margen_error)

#7. Pasar a formato largo:
df <- df %>% select(-fecha,-n) %>% gather(candidato, int_voto, ivan_duque,gustavo_petro,sergio_fajardo,german_vargas_lleras,humberto_delacalle)

#8. Crear data frames por candidato:
id <- df %>% filter(candidato=="ivan_duque") 
gp <- df %>% filter(candidato=="gustavo_petro") 
sf <- df %>% filter(candidato=="sergio_fajardo") 
gvl <- df %>% filter(candidato=="german_vargas_lleras") 
hdlc <- df %>% filter(candidato=="humberto_delacalle") 
```

<br>

#### *Estimación*
<br>
El plato mixto también se prepara con [RStan](https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started), y en este caso voy a usar al candidato [Iván Duque](https://www.ivanduque.com/) como ejemplo. 

El código es miedoso, y tuve que verificarlo varias veces con el paquete [*rethinking*](https://github.com/rmcelreath/rethinking) de McElreath. Pero logra su cometido.

El modelo utiliza el data frame *id*, así como los priors $\small\mu_{candidato}=39$, $\small\sigma_{candidato}=4$ y para la matriz de correlaciones LKJ $\small\eta=2$. Toda la receta va en el siguiente objeto *duque.stan*:
<br>
```{stan output.var="duque"}
data{
    int<lower=1> N;
    int<lower=1> N_encuestadora;
    real int_voto[N];
    int encuestadora[N];
    real muestra_int_voto[N];
    real m_error[N];
    real dd[N];
    real tipo[N];
}
parameters{
    vector[N_encuestadora] b4_encuestadora;
    vector[N_encuestadora] b3_encuestadora;
    vector[N_encuestadora] b2_encuestadora;
    vector[N_encuestadora] b1_encuestadora;
    vector[N_encuestadora] a_encuestadora;
    real a;
    real b1;
    real b2;
    real b3;
    real b4;
    vector<lower=0>[5] s_encuestadora;
    real<lower=0> s;
    corr_matrix[5] Rho;
}
transformed parameters{
    vector[5] v_a_encuestadorab1_encuestadorab2_encuestadorab3_encuestadorab4_encuestadora[N_encuestadora];
    vector[5] Mu_ab1b2b3b4;
    cov_matrix[5] SRS_s_encuestadoraRho;
    for ( j in 1:N_encuestadora ) {
        v_a_encuestadorab1_encuestadorab2_encuestadorab3_encuestadorab4_encuestadora[j,1] = a_encuestadora[j];
        v_a_encuestadorab1_encuestadorab2_encuestadorab3_encuestadorab4_encuestadora[j,2] = b1_encuestadora[j];
        v_a_encuestadorab1_encuestadorab2_encuestadorab3_encuestadorab4_encuestadora[j,3] = b2_encuestadora[j];
        v_a_encuestadorab1_encuestadorab2_encuestadorab3_encuestadorab4_encuestadora[j,4] = b3_encuestadora[j];
        v_a_encuestadorab1_encuestadorab2_encuestadorab3_encuestadorab4_encuestadora[j,5] = b4_encuestadora[j];
    }
    for ( j in 1:5 ) {
        Mu_ab1b2b3b4[1] = a;
        Mu_ab1b2b3b4[2] = b1;
        Mu_ab1b2b3b4[3] = b2;
        Mu_ab1b2b3b4[4] = b3;
        Mu_ab1b2b3b4[5] = b4;
    }
    SRS_s_encuestadoraRho = quad_form_diag(Rho,s_encuestadora);
}
model{
    vector[N] m;
    Rho ~ lkj_corr( 2 );
    s ~ cauchy( 0 , 5 );
    s_encuestadora ~ cauchy( 0 , 5 );
    b4 ~ normal( 0 , 10 );
    b3 ~ normal( 0 , 10 );
    b2 ~ normal( 0 , 10 );
    b1 ~ normal( 0 , 10 );
    a ~ normal( 39 , 4 );
    v_a_encuestadorab1_encuestadorab2_encuestadorab3_encuestadorab4_encuestadora ~ multi_normal( Mu_ab1b2b3b4 , SRS_s_encuestadoraRho );
    for ( i in 1:N ) {
        m[i] = a_encuestadora[encuestadora[i]] + b1_encuestadora[encuestadora[i]] *      muestra_int_voto[i] + b2_encuestadora[encuestadora[i]] * m_error[i] +      b3_encuestadora[encuestadora[i]] * dd[i] + b4_encuestadora[encuestadora[i]] *      tipo[i];
    }
    int_voto ~ normal( m , s );
}
generated quantities{
    vector[N] m;
    real dev;
    dev = 0;
    for ( i in 1:N ) {
        m[i] = a_encuestadora[encuestadora[i]] + b1_encuestadora[encuestadora[i]] *      muestra_int_voto[i] + b2_encuestadora[encuestadora[i]] * m_error[i] +      b3_encuestadora[encuestadora[i]] * dd[i] + b4_encuestadora[encuestadora[i]] *      tipo[i];
    }
    dev = dev + (-2)*normal_lpdf( int_voto | m , s );
}

```
<br>
Ahora nos vamos a RStan para prepara el plato:
<br>
```{r results = "hide",message=F}
library(rstan)
options(mc.cores = parallel::detectCores())
duque_fit <- stan(file='duque.stan',data=list(N=17,N_encuestadora=6,int_voto=id$int_voto,encuestadora=id$encuestadora, muestra_int_voto=id$muestra_int_voto,m_error=id$m_error,dd=id$dd,tipo=id$tipo),control=list(adapt_delta=0.95),iter=4000,chains=4)
```
<br>
El plato mixto necesita mucho más tiempo para cocinarse que el simple, pero al final sale. Aunque *duque.stan* tiene muchas divergencias iniciales en el muestreo, el plato sale del horno sin quemarse. 

<br>
``` {r, echo=FALSE, message=F}
library(bayesplot)
color_scheme_set("orange")
  
# Crear matriz de muestras de la distribucion posterior
posterior <- as.matrix(duque_fit)
  
#Trace plot para los parametros de interes
mcmc_trace(posterior,pars=c("m[1]","m[2]","m[3]","m[4]","m[5]","m[6]","m[7]","m[8]","m[9]","m[10]","m[11]","m[12]","m[13]","m[14]","m[15]","m[16]","m[17]"))
```
<br>

El resultado es un plato mixto que sabe mejor que el plato simple. Puede que el sabor sea *demasiado* bueno (i.e. [*overfitting*](https://xkcd.com/1122/)).

Para los que tuvieron la paciencia de bajar hasta acá, va un premio: los valores observados para Iván Duque en las encuestas (en naranja) vs. los valores estimados por el plato mixto (en rojo). 

<br>
``` {r, echo=FALSE, message=F}
library(ggplot2)
# Parámetros vs Observados
par <- posterior %>% as.tibble() %>% select(127:143) %>% summarize_all(funs(mean)) %>% t()
obs <- tibble(int_voto = id$int_voto,n = seq(from=1,to=17,by=1))
par_obs <- cbind(par,obs)
ggplot(par_obs, aes(x=n))+
    geom_point(aes(y=int_voto),size=4,color="orangered")+
    geom_point(aes(y=par),shape=10,size=5,color="red2")+
    theme_classic()+labs(y="intencion de voto",x="")+scale_x_continuous(breaks=c(1:17))+
    ylim(values=c(30,50))
```
<br>

Este plato tiene muchísimos parámetros, así que abajo sólo presento los más relevantes: 
<br>

``` {r}
library(bayesplot)
posterior <- as.matrix(duque_fit)
color_scheme_set("orange")
mcmc_areas(posterior,prob=0.9,prob_outer = 0.99,point_est="mean",pars=c("m[1]","m[2]","m[3]","m[4]","m[5]","m[6]","m[7]","m[8]","m[9]","m[10]","m[11]","m[12]","m[13]","m[14]","m[15]","m[16]","m[17]"))
```
<br>
<br>
Para todo lo demás [shinystan](https://github.com/stan-dev/shinystan).
<br>
<br>
``` {r}
library(shinystan)
launch_shinystan(duque_fit)
```
***
## Referencias
<br>
McElreath, R. (2015). [Statistical Rethinking](http://xcelab.net/rm/statistical-rethinking/). Texts in Statistical Science. Capítulo 13.
<br>
<br>
McElreath, R. ["Multilevel Regression as Default"](http://elevanth.org/blog/2017/08/24/multilevel-regression-as-default/)
<br>
<br>
Gelman, A. ["Multilevel (Hierarchical) Modeling:
What It Can and Cannot Do"](http://www.stat.columbia.edu/~gelman/research/published/multi2.pdf).
<br>
<br>
[Entrada del blog stlaPblog sobre LKJ en Stan](http://stla.github.io/stlapblog/posts/StanLKJprior.html)
<br>
<br>
Lewandowski, D., Kurowicka, D., & Joe, H. (2009). [Generating random correlation matrices based on vines and extended onion method. Journal of multivariate analysis](https://www.sciencedirect.com/science/article/pii/S0047259X09000876), 100(9), 1989-2001.
<br>
<br>
Stan Development Team. 2017. RStan: the R interface to Stan. R package version 2.16.2. http://mc-stan.org
<br>
<br>
Stan Development Team. 2017. ShinyStan: Interactive Visual and Numerical Diagnostics and Posterior Analysis for Bayesian Models. R package version 2.4.0.   http://mc-stan.org
<br>
<br>
Silver, N. (2017) ["The Media has a probability problem"](https://fivethirtyeight.com/features/the-media-has-a-probability-problem/?ex_cid=story-twitter). 538.
